{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322af06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "from logger_config import logger\n",
    "\n",
    "from typing import Annotated, Sequence, List, Literal \n",
    "from pydantic import BaseModel, Field \n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults \n",
    "from langgraph.types import Command \n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.prebuilt import create_react_agent \n",
    "from IPython.display import Image, display \n",
    "from dotenv import load_dotenv\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "import pprint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd4f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198790d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_search = TavilySearchResults(max_results=1)\n",
    "\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "721dd2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'5\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl_tool.invoke(\"x = 5; print(x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44955f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Supervisor(BaseModel):\n",
    "    next: Literal[\"enhancer\", \"researcher\", \"coder\"] = Field(\n",
    "        description=\"Determines which specialist to activate next in the workflow sequence: \"\n",
    "                    \"'enhancer' when user input requires clarification, expansion, or refinement, \"\n",
    "                    \"'researcher' when additional facts, context, or data collection is necessary, \"\n",
    "                    \"'coder' when implementation, computation, or technical problem-solving is required.\"\n",
    "    )\n",
    "    reason: str = Field(\n",
    "        description=\"Detailed justification for the routing decision, explaining the rationale behind selecting the particular specialist and how this advances the task toward completion.\"\n",
    "    )\n",
    "\n",
    "def supervisor_node(state: MessagesState) -> Command[Literal[\"enhancer\", \"researcher\", \"coder\"]]:\n",
    "\n",
    "    system_prompt = ('''\n",
    "                 \n",
    "        You are a workflow supervisor managing a team of three specialized agents: Prompt Enhancer, Researcher, and Coder. Your role is to orchestrate the workflow by selecting the most appropriate next agent based on the current state and needs of the task. Provide a clear, concise rationale for each decision to ensure transparency in your decision-making process.\n",
    "\n",
    "        **Team Members**:\n",
    "        1. **Prompt Enhancer**: Always consider this agent first. They clarify ambiguous requests, improve poorly defined queries, and ensure the task is well-structured before deeper processing begins.\n",
    "        2. **Researcher**: Specializes in information gathering, fact-finding, and collecting relevant data needed to address the user's request.\n",
    "        3. **Coder**: Focuses on technical implementation, calculations, data analysis, algorithm development, and coding solutions.\n",
    "\n",
    "        **Your Responsibilities**:\n",
    "        1. Analyze each user request and agent response for completeness, accuracy, and relevance.\n",
    "        2. Route the task to the most appropriate agent at each decision point.\n",
    "        3. Maintain workflow momentum by avoiding redundant agent assignments.\n",
    "        4. Continue the process until the user's request is fully and satisfactorily resolved.\n",
    "\n",
    "        Your objective is to create an efficient workflow that leverages each agent's strengths while minimizing unnecessary steps, ultimately delivering complete and accurate solutions to user requests.\n",
    "                 \n",
    "    ''')\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},  \n",
    "    ] + state[\"messages\"] \n",
    "\n",
    "    response = llm.with_structured_output(Supervisor).invoke(messages)\n",
    "\n",
    "    goto = response.next\n",
    "    reason = response.reason\n",
    "\n",
    "    logger.info(f\"--- Workflow Transition: Supervisor → {goto.upper()} ---\")\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=reason, name=\"supervisor\")\n",
    "            ]\n",
    "        },\n",
    "        goto=goto,  \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60be5ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhancer_node(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "\n",
    "    \"\"\"\n",
    "        Enhancer agent node that improves and clarifies user queries.\n",
    "        Takes the original user input and transforms it into a more precise,\n",
    "        actionable request before passing it to the supervisor.\n",
    "    \"\"\"\n",
    "   \n",
    "    system_prompt = (\n",
    "        \"You are a Query Refinement Specialist with expertise in transforming vague requests into precise instructions. Your responsibilities include:\\n\\n\"\n",
    "        \"1. Analyzing the original query to identify key intent and requirements\\n\"\n",
    "        \"2. Resolving any ambiguities without requesting additional user input\\n\"\n",
    "        \"3. Expanding underdeveloped aspects of the query with reasonable assumptions\\n\"\n",
    "        \"4. Restructuring the query for clarity and actionability\\n\"\n",
    "        \"5. Ensuring all technical terminology is properly defined in context\\n\\n\"\n",
    "        \"Important: Never ask questions back to the user. Instead, make informed assumptions and create the most comprehensive version of their request possible.\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},  \n",
    "    ] + state[\"messages\"]  \n",
    "\n",
    "    enhanced_query = llm.invoke(messages)\n",
    "\n",
    "    logger.info(f\"--- Workflow Transition: Prompt Enhancer → Supervisor ---\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [  \n",
    "                HumanMessage(\n",
    "                    content=enhanced_query.content, \n",
    "                    name=\"enhancer\"  \n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\", \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28d15f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_node(state: MessagesState) -> Command[Literal[\"validator\"]]:\n",
    "\n",
    "    \"\"\"\n",
    "        Research agent node that gathers information using Tavily search.\n",
    "        Takes the current task state, performs relevant research,\n",
    "        and returns findings for validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    research_agent = create_react_agent(\n",
    "        llm,  \n",
    "        tools=[tavily_search],  \n",
    "        state_modifier= \"You are an Information Specialist with expertise in comprehensive research. Your responsibilities include:\\n\\n\"\n",
    "            \"1. Identifying key information needs based on the query context\\n\"\n",
    "            \"2. Gathering relevant, accurate, and up-to-date information from reliable sources\\n\"\n",
    "            \"3. Organizing findings in a structured, easily digestible format\\n\"\n",
    "            \"4. Citing sources when possible to establish credibility\\n\"\n",
    "            \"5. Focusing exclusively on information gathering - avoid analysis or implementation\\n\\n\"\n",
    "            \"Provide thorough, factual responses without speculation where information is unavailable.\"\n",
    "    )\n",
    "\n",
    "    result = research_agent.invoke(state)\n",
    "\n",
    "    logger.info(f\"--- Workflow Transition: Researcher → Validator ---\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [ \n",
    "                HumanMessage(\n",
    "                    content=result[\"messages\"][-1].content,  \n",
    "                    name=\"researcher\"  \n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"validator\", \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10251541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_node(state: MessagesState) -> Command[Literal[\"validator\"]]:\n",
    "\n",
    "    code_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[python_repl_tool],\n",
    "        state_modifier=(\n",
    "            \"You are a coder and analyst. Focus on mathematical calculations, analyzing, solving math questions, \"\n",
    "            \"and executing code. Handle technical problem-solving and data tasks.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    result = code_agent.invoke(state)\n",
    "\n",
    "    logger.info(f\"--- Workflow Transition: Coder → Validator ---\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"coder\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"validator\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69a7dc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt providing clear instructions to the validator agent\n",
    "system_prompt = '''\n",
    "    Your task is to ensure reasonable quality. \n",
    "    Specifically, you must:\n",
    "    - Review the user's question (the first message in the workflow).\n",
    "    - Review the answer (the last message in the workflow).\n",
    "    - If the answer addresses the core intent of the question, even if not perfectly, signal to end the workflow with 'FINISH'.\n",
    "    - Only route back to the supervisor if the answer is completely off-topic, harmful, or fundamentally misunderstands the question.\n",
    "    \n",
    "    - Accept answers that are \"good enough\" rather than perfect\n",
    "    - Prioritize workflow completion over perfect responses\n",
    "    - Give benefit of doubt to borderline answers\n",
    "    \n",
    "    Routing Guidelines:\n",
    "    1. 'supervisor' Agent: ONLY for responses that are completely incorrect or off-topic.\n",
    "    2. Respond with 'FINISH' in all other cases to end the workflow.\n",
    "'''\n",
    "\n",
    "class Validator(BaseModel):\n",
    "    next: Literal[\"supervisor\", \"FINISH\"] = Field(\n",
    "        description=\"Specifies the next worker in the pipeline: 'supervisor' to continue or 'FINISH' to terminate.\"\n",
    "    )\n",
    "    reason: str = Field(\n",
    "        description=\"The reason for the decision.\"\n",
    "    )\n",
    "\n",
    "def validator_node(state: MessagesState) -> Command[Literal[\"supervisor\", \"__end__\"]]:\n",
    "\n",
    "    user_question = state[\"messages\"][0].content\n",
    "    agent_answer = state[\"messages\"][-1].content\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_question},\n",
    "        {\"role\": \"assistant\", \"content\": agent_answer},\n",
    "    ]\n",
    "\n",
    "    response = llm.with_structured_output(Validator).invoke(messages)\n",
    "\n",
    "    goto = response.next\n",
    "    reason = response.reason\n",
    "\n",
    "    if goto == \"FINISH\" or goto == END:\n",
    "        goto = END  \n",
    "        logger.info(\" --- Transitioning to END ---\")  \n",
    "    else:\n",
    "        logger.info(f\"--- Workflow Transition: Validator → Supervisor ---\")\n",
    " \n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=reason, name=\"validator\")\n",
    "            ]\n",
    "        },\n",
    "        goto=goto, \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcea35a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_node) \n",
    "graph.add_node(\"enhancer\", enhancer_node)  \n",
    "graph.add_node(\"researcher\", research_node) \n",
    "graph.add_node(\"coder\", code_node) \n",
    "graph.add_node(\"validator\", validator_node)  \n",
    "\n",
    "graph.add_edge(START, \"supervisor\")  \n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3928ef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 15:55:51 | 3451679309.py | <module> | Line: 1 | INFO | %%{init: {'flowchart': {'curve': 'linear'}}}%%\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tsupervisor(supervisor)\n",
      "\tenhancer(enhancer)\n",
      "\tresearcher(researcher)\n",
      "\tcoder(coder)\n",
      "\tvalidator(validator)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> supervisor;\n",
      "\tsupervisor -.-> enhancer;\n",
      "\tsupervisor -.-> researcher;\n",
      "\tsupervisor -.-> coder;\n",
      "\tenhancer -.-> supervisor;\n",
      "\tresearcher -.-> validator;\n",
      "\tcoder -.-> validator;\n",
      "\tvalidator -.-> supervisor;\n",
      "\tvalidator -.-> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(app.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef7cdc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 15:49:35 | 2193137005.py | supervisor_node | Line: 42 | INFO | --- Workflow Transition: Supervisor → RESEARCHER ---\n",
      "2025-05-19 15:49:35 | 3656673417.py | <module> | Line: 15 | INFO | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Output from node 'supervisor':\"\n",
      "HumanMessage(content='The user query is about weather, which requires factual information and data collection. The researcher agent is best suited to gather the relevant data needed to provide an accurate answer.', additional_kwargs={}, response_metadata={}, name='supervisor', id='2950b2e0-22ba-4d2f-b9fc-7fcb8fa69cbf')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 15:49:39 | 2625631429.py | research_node | Line: 23 | INFO | --- Workflow Transition: Researcher → Validator ---\n",
      "2025-05-19 15:49:39 | 3656673417.py | <module> | Line: 15 | INFO | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Output from node 'researcher':\"\n",
      "HumanMessage(content='The current weather in Chennai is patchy light rain with thunder. The temperature is 33.4°C or 92.1°F, and the humidity is 67%. The wind speed is 13.3 km/h or 8.3 mph from the east-southeast direction. The atmospheric pressure is 1001.0 mb or 29.56 in, and the visibility is 5.0 km or 3.0 miles. The UV index is 3.3.', additional_kwargs={}, response_metadata={}, name='researcher', id='a94706d6-b96d-422e-b027-6500665428d0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 15:49:40 | 1262067928.py | validator_node | Line: 45 | INFO |  --- Transitioning to END ---\n",
      "2025-05-19 15:49:40 | 3656673417.py | <module> | Line: 15 | INFO | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Output from node 'validator':\"\n",
      "HumanMessage(content='Answered the user query about Chennai weather.', additional_kwargs={}, response_metadata={}, name='validator', id='f1c6e9a6-8208-4154-8719-905f9cc399b5')\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"Weather in Chennai\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "for event in app.stream(inputs):\n",
    "    for key, value in event.items():\n",
    "        if value is None:\n",
    "            continue\n",
    "        last_message = value.get(\"messages\", [])[-1] if \"messages\" in value else None\n",
    "        if last_message:\n",
    "            pprint.pprint(f\"Output from node '{key}':\")\n",
    "            pprint.pprint(last_message, indent=2, width=80, depth=None)\n",
    "            logger.info(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32cd812f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 15:55:55 | 2193137005.py | supervisor_node | Line: 42 | INFO | --- Workflow Transition: Supervisor → RESEARCHER ---\n",
      "2025-05-19 15:55:55 | 1400057110.py | <module> | Line: 12 | INFO | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Output from node 'supervisor':\"\n",
      "{ 'messages': [ HumanMessage(content='To gather required data and resources for calculating the 20th Fibonacci number.', additional_kwargs={}, response_metadata={}, name='supervisor', id='19104510-806e-42fc-88e2-0ceb71d349ae')]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 15:56:07 | 2625631429.py | research_node | Line: 23 | INFO | --- Workflow Transition: Researcher → Validator ---\n",
      "2025-05-19 15:56:07 | 1400057110.py | <module> | Line: 12 | INFO | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Output from node 'researcher':\"\n",
      "{ 'messages': [ HumanMessage(content='The 20th Fibonacci number is 6,765.', additional_kwargs={}, response_metadata={}, name='researcher', id='2da834d1-eabb-4584-8375-e14290133054')]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 15:56:07 | 1262067928.py | validator_node | Line: 45 | INFO |  --- Transitioning to END ---\n",
      "2025-05-19 15:56:07 | 1400057110.py | <module> | Line: 12 | INFO | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Output from node 'validator':\"\n",
      "{ 'messages': [ HumanMessage(content='Provided the 20th Fibonacci number directly.', additional_kwargs={}, response_metadata={}, name='validator', id='db7f1c18-05a5-4af7-bb02-b9b66bb94724')]}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"Give me the 20th fibonacci number\"),\n",
    "    ]\n",
    "}\n",
    "for event in app.stream(inputs):\n",
    "    for key, value in event.items():\n",
    "        if value is None:\n",
    "            continue\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "        logger.info(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6feeec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
